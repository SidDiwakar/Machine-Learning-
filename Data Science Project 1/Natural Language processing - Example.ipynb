{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language processing - Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import the importent libraries \n",
    "import nltk\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# text_lowercase :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hey, did you know that the summer break is coming? amazing right !! it's only 5 more days !!\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We lowercase the text to reduce the size of the vocabulary of our text data.\n",
    "def text_lowercase(text):\n",
    "    return text.lower()\n",
    "\n",
    "input_str = \"Hey, did you know that the summer break is coming? Amazing right !! It's only 5 more days !!\"\n",
    "text_lowercase(input_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove_numbers : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are  balls in this bag, and  in the other one.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can either remove numbers or convert the numbers into their textual representations.\n",
    "# We can use regular expressions to remove the numbers.\n",
    "def remove_numbers(text):\n",
    "    #The r means that the string is to be treated as a raw string, which means all escape codes will be ignored.\n",
    "    # \\D+ is checking if the whole string is a non-digit expression.\n",
    "    result = re.sub(r'\\d+', '', text)\n",
    "    return result\n",
    "\n",
    "input_str = \"There are 3 balls in this bag, and 12 in the other one.\"\n",
    "remove_numbers(input_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert numbers in words :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are three balls in this bag, and twelve in the other one.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also convert the numbers into words. This can be done by using the inflect library.\n",
    "\n",
    "import inflect\n",
    "p= inflect.engine()\n",
    "\n",
    "\n",
    "def convert_num_in_words(text):\n",
    "    \n",
    "    temp_string = text.split()\n",
    "    new_string = []\n",
    "    \n",
    "    for word in temp_string:\n",
    "        \n",
    "        if word.isdigit():\n",
    "            \n",
    "            temp = p.number_to_words(word) # if word is a number convert it into word\n",
    "            new_string.append(temp)\n",
    "            \n",
    "        else:\n",
    "            new_string.append(word) # if word is a word\n",
    "            \n",
    "    temp_string = ' '.join(new_string)\n",
    "    return temp_string\n",
    "\n",
    "input_str = 'There are 3 balls in this bag, and 12 in the other one.'\n",
    "convert_num_in_words(input_str)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove punctuation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hey did you know that the summer break is coming Amazing right  Its only 5 more days '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We remove punctuations so that we don’t have different forms of the same word. If we don’t remove the punctuation,\n",
    "# then been. been, been! will be treated separately.\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    translator = str.maketrans('','',string.punctuation)\n",
    "    return text.translate(translator)\n",
    "\n",
    "input_str = \"Hey, did you know that the summer break is coming? Amazing right !! It's only 5 more days !!\"\n",
    "remove_punctuation(input_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove whitespaces :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"we don't need the given questions\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_whitespace(text):\n",
    "    return \" \".join(text.split())\n",
    "\n",
    "input_str = \"   we    don't need   the     given     questions\"\n",
    "remove_whitespace(input_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove default stopwords :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words(\"English\"))\n",
    "    word_tokens  = word_tokenize(text)\n",
    "    filtered_text = [word for word in word_tokens if word not in stop_words]\n",
    "    return filtered_text\n",
    "\n",
    "example_text = \"This is a sample sentence and we are going to remove the stopwords from this.\"\n",
    "remove_stopwords(example_text)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove stemming :  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tockenize\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# stem words in the list of tokenised words \n",
    "def stem_words(text):\n",
    "    word_tokens = word_tokenize(text)\n",
    "    stems = [stemmer.stem(word) for word in word_tokens]\n",
    "    return stems\n",
    "\n",
    "text = 'data science uses scientific methods algorithms and many types of processes'\n",
    "stem_words(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization :\n",
    "     lemmatization also converts a word to its root form. The only difference is that lemmatization ensures that the root\n",
    "     word belongs to the language. We will get valid words if we use lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "lemmatizer  = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_word(text):\n",
    "    \n",
    "    word_tokens = word_tokenize(text) \n",
    "    lemmas = [lemmatizer.lemmatize(word, pos ='v') for word in word_tokens]\n",
    "    return lemmas\n",
    "text = 'data science uses scientific methods algorithms and many types of processes'\n",
    "lemmatize_word(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
